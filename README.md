# 여행 트렌드 검색 분석, 예측 앱 사이트

## 목차
- [여행 트렌드 검색 분석, 예측 앱 사이트](#여행-트렌드-검색-분석-예측-앱-사이트)
  - [목차](#목차)
  - [1. 개요](#1-개요)
  - [2. 기능](#2-기능)
  - [3. 프로젝트 문제 해결](#3-프로젝트-문제-해결)
  - [4. 예상되는 문제](#4-예상되는-문제)

## 1. 개요

 - ## 1) 기회 의도
   - 과거 해외 및 국내 여행 검색 순위에 따라 트렌드를 확인할 수 있게 해주는 앱니다.
   - 과거의 데이터를 통해 이후 미래의 검색 트렌드를 예측하게 해주는 앱입니다.

    > ![image](https://github.com/wonjun12/Travel-Trend-App-Dashboard/assets/108748094/42b1c146-353e-42fd-8185-81f8e24ed0f4)



 - ## 2) 사용 기술 
  ![aws ec2](https://img.shields.io/badge/Amazon_Web_Server-EC2-red) ![Anaconda](https://img.shields.io/badge/Python-Anaconda-blue) ![Streamlit](https://img.shields.io/badge/Python-Streamlit-blue) ![Numpy](https://img.shields.io/badge/Python-Numpy-blue)
 ![Pandas](https://img.shields.io/badge/Python-Pandas-blue)
 ![Joblib](https://img.shields.io/badge/Python-Joblib-blue)
 ![Plotly](https://img.shields.io/badge/Python-Plotly.express-blue)


 - ## 3) 링크 
    - 사이트 : [ec2-52-78-84-125.ap-northeast-2.compute.amazonaws.com:10000/](http://ec2-52-78-84-125.ap-northeast-2.compute.amazonaws.com:10000/)
    - 다운로드
      - [국내 여행](https://www.bigdata-culture.kr/bigdata/user/data_market/detail.do?id=25c89d50-1e55-11eb-a4e6-a9a03a61580b)
      - [해외 여행](https://www.bigdata-culture.kr/bigdata/user/data_market/detail.do?id=2ed02b20-1e55-11eb-a4e6-a9a03a61580b)


## 2. 기능
  - **Github의 Actions를 통한 CI/CD 자동 배포 설정**
  - **About**
    - 해당 앱이 어떤 앱인지 설명해줍니다.
    - 사용한 데이터의 출처를 보여줍니다.
    - 사용한 데이터가 무엇인지 보여줍니다.
  - **해외 여행**
    - 지정한 날짜를 기준으로 검색된 해외 여행 검색 순위 및 검색 량을알려줍니다.
    - 모바일, PC, 전체 검색량도 같이 보여줍니다.
    - 여행지에 따라서 어떻게 검색했는지 종류와 비율을 알려줍니다.
  - **국내 여행**
    - 지정한 날짜를 기준으로 검색된 해외 여행 검색 순위 및 검색 량을알려줍니다.
    - 모바일, PC, 전체 검색량도 같이 보여줍니다.
    - 여행지에 따라서 어떻게 검색했는지 종류와 비율을 알려줍니다.
  - **ml**
    - Prophet 라이브러리를 이용해 검색량 미래 예측을 시행합니다.
    - 원하는 날짜 범위의 해외, 국내 여행의 검색량을 예측하고, 순위를 나타냅니다.
  - **Data Upload**
    - 최신 데이터가 추가 되거나, 과거 없는 데이터 추가시에 쉽게 추가할 수 있습니다.
   ![image](https://github.com/wonjun12/Travel-Trend-App-Dashboard/assets/108748094/23c2727a-6a33-4afb-a154-3f0cb2c9c82e)
![image](https://github.com/wonjun12/Travel-Trend-App-Dashboard/assets/108748094/f3d143a7-0638-4fb0-89f6-561646f74abd)



## 3. 프로젝트 문제 해결
  1. ### **프로젝트에 사용할 파일들이 일별로 너무 많아 따로 작업을 해야했다.**
       - 파일이 너무 많아 하나씩 합치는 것은 불가능하다고 판단하여, 처음 찾아봤을때 특정 프로그램을 사용해야한다고 했었다.
       - 하지만, 약 1000개 이상의 파일을 합치는데 시간이 오래걸리기도 하고 렉이 걸려 안된다고 판단하고 다른 방법을 찾으려 했다.
       - 이를 위해 찾은 방법은 **os.path.join**을 통해 파일을 한꺼번에 찾아내어 **glob.glob**를 거쳐서 파일의 경로를 찾아 내는 방법을 사용하였다.
       - **pandas의 concat**을 사용해 한꺼번에 합치도록 설정했는데, 이를 위해서는 컬럼이 같아야하는 조건이 붙기에 사전에 몇몇의 데이터를 확인하여 컬럼이 같은지를 확인했다.
  2. ### **파일 정리를 완료 후 새로 csv파일을 불러오니 날짜 데이터가 String 타입이였다.**
       - 개인적인 생각으로는 ','(쉼표)로 구분 되어있는 파일이다보니 한번 불러올때 Object로 불러오는 것으로 보고 있다.
       - 불어올때 String이다보니 처음에는 당황하긴 했지만 **pandas의 datatime**으로 변경 함수를 활용해 변경하였다.
  3. ### **예측 모델 Prophet를 사용할 수 밖에 없었다.**
       - 처음에는 LinearRegression으로 모델 학습을 진행했었는데, 검색량을 예측하기 위해서는 날짜와 순위의 정보를 가지고있어야하는데 모듈을 돌리기 위해, OneHotEncoder와 LabelEncoder를 통해 인코더를 진행 후 학습과 예측을 실행하였지만 정답률은 10~20% 내외로 매우 낮은 정답률이 나왔다.
       - 동일한 방법으로 LogisticRegression의 분류 학습을 진행 했을때도, 순위 분류를 제대로 진행하지 못했다. 해당 문제는 제대로 학습시키지 못한 문제도 있었고, 같은 날의 동일한 값이 여러개 있다보니 제대로 예측하지 못했던 것 같다.
       - Prophet의 모델을 통해 순위를 예측했었지만, 제대로 되지 않았고, 검색량을 날짜에 비롯해 예측하니 어느정도 맞았다.
       - 하지만, 몇몇의 경우 데이터가 부족해 비정상적인 값이 나오기도 했는데 해당 데이터의 경우 아예 학습 데이터에서 제외 시켰더니, 맞게 나왔다.
  4. ### **joblib를 통해 학습한 모델을 파일화 시켰다.**
       - 모델을 파일화 시키는 과정에서 국내, 해외를 동시에 진행하지 할 수가 없어 2가지의 모델을 학습했는데 이를 파일로 저장하는 과정에서 객체로 변경해 2개를 같은 파일로 저장시켜 사용했다.
  5. ### **파일을 업로드하는 과정에서 Error가 발생했고, 중복되는 값이 계속 들어갔다.**
       - 파일을 처리하고 가공하는 과정에서 오류를 일으키는 경우가 많아 제공한 사이트 이외의 파일을 업로드 할 시 Try-Except 예외처리로 에러를 일으키도록 설정해서 다시 올리라고 안내를 했다.
       - 만약 다운받은 파일을 중복해서 여러개 올리는 경우가 있는데, 이는 하나의 빈 DataFrame을 만들어 임시적으로 전부 겹치도록 만들었고, 임시 DataFrame에서 중복처리를 하여 못 올린다고 안내하였다.

## 4. 예상되는 문제
  1. **클라이언트에서 파일 업로드 후 로컬에서 개발하여 Git을 통해 자동 배포시에 에러를 일으킨다.**
     - 이는 Git 문제로 서버에서는 새로운 파일이 적혀져 로컬에서 넣은 새로운 파일이 제대로 Pull이 안될경우가 생긴다.
     - 해결하기 위해서는 CSV파일을 다른 곳에 저장시키거나, 파일을 건들지 않고 다른 코드들만 건드는 방법으로 하는것이 좋아보인다.
  2. **시간이 지나 예측 모델이 정상적으로 작동 하지 않는다.** 
     - 시간이 지날 수록 예측할수 있는 모델의 데이터가 적어 제대로 된 예측이 불가능하다고 생각한다.
     - 또한 사이트의 오류로 인해 제대로 다운 받지 못한 데이터가 매우 많기도해서 시간이 지난다면 모델이 정상적으로 예측을 할수 없을것이다라고 생각한다.



